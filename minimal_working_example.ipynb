{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training via Denoising for Molecular Property Prediction\n",
    "\n",
    "Clone the repository: \n",
    "```\n",
    "git clone https://github.com/shehzaidi/pre-training-via-denoising.git\n",
    "cd pre-training-via-denoising\n",
    "```\n",
    "\n",
    "Create a virtual environment containing the dependencies and activate it:\n",
    "```\n",
    "conda env create -f environment.yml\n",
    "conda activate pvd\n",
    "```\n",
    "\n",
    "Install the package into the environment:\n",
    "```\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# pip install -e .\n",
    "# pip install pytorch_lightning.plugins\n",
    "# pip install torch_scatter\n",
    "# pip install torch_geometric\n",
    "# pip install toch_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: activate: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!source activate pvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # sometimes needed to avoid mkl-service error\n",
    "import os\n",
    "from os.path import dirname, join, exists\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import wandb\n",
    "from typing import Optional, Callable, List, Tuple\n",
    "import glob\n",
    "import ase\n",
    "import re\n",
    "import warnings\n",
    "from abc import abstractmethod, ABCMeta\n",
    "import math\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pytorch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.utilities import rank_zero_only, rank_zero_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torch.nn.functional import mse_loss, l1_loss\n",
    "from torch.utils.data import Subset\n",
    "from torch.autograd import grad\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.data import InMemoryDataset, download_url, extract_zip, Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_cluster import radius_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify arguments\n",
    "args = argparse.Namespace(\n",
    "    activation = 'silu',\n",
    "    aggr = 'add',\n",
    "    atom_filter = -1,\n",
    "    attn_activation = 'silu',\n",
    "    batch_size = 2,\n",
    "    conf = None,\n",
    "    cutoff_lower = 0.0,\n",
    "    cutoff_upper = 5.0,\n",
    "    dataset = 'PCQM4MV2',\n",
    "    dataset_arg = None,\n",
    "    dataset_root = 'data/pcq',\n",
    "    denoising_only = True,\n",
    "    denoising_weight = 1.0,\n",
    "    derivative = False,\n",
    "    distance_influence = 'both',\n",
    "    early_stopping_patience = 150,\n",
    "    ema_alpha_dy = 1.0,\n",
    "    ema_alpha_y = 1.0,\n",
    "    embedding_dimension = 256,\n",
    "    energy_weight = 0.0,\n",
    "    force_weight = 1.0,\n",
    "    inference_batch_size = 2,\n",
    "    job_id = 'pretraining',\n",
    "    layernorm_on_vec = 'whitened',\n",
    "    load_model = None,\n",
    "    log_dir = 'experiments/',\n",
    "    lr = 0.0004,\n",
    "    lr_cosine_length = 400000,\n",
    "    lr_factor = 0.8,\n",
    "    lr_min = 1e-07,\n",
    "    lr_patience = 15,\n",
    "    lr_schedule = 'cosine',\n",
    "    lr_warmup_steps = 10, # 10000\n",
    "    max_num_neighbors = 32,\n",
    "    max_z = 100,\n",
    "    model = 'equivariant-transformer',\n",
    "    neighbor_embedding = True,\n",
    "    ngpus = 1,\n",
    "    num_epochs = 2, # 30\n",
    "    num_heads = 8,\n",
    "    num_layers = 2, # 8\n",
    "    num_nodes = 1,\n",
    "    num_rbf = 64,\n",
    "    num_steps = 400, # 400000\n",
    "    num_workers = 6,\n",
    "    output_model = 'Scalar',\n",
    "    output_model_noise = 'VectorOutput',\n",
    "    position_noise_scale = 0.04,\n",
    "    precision = 32,\n",
    "    pretrained_model = None,\n",
    "    prior_model = None,\n",
    "    rbf_type = 'expnorm',\n",
    "    redirect = False,\n",
    "    reduce_op = 'add',\n",
    "    save_interval = 10,\n",
    "    seed = 1,\n",
    "    splits = None,\n",
    "    standardize = False, \n",
    "    test_interval = 10,\n",
    "    test_size = 100,\n",
    "    train_size = 100, # None\n",
    "    trainable_rbf = False,   \n",
    "    val_size = 10,\n",
    "    wandb_notes = '',\n",
    "    weight_decay = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play around with the input parameters\n",
    "args.position_noise_scale = 0.04\n",
    "args.num_epochs = 3\n",
    "args.test_size = 100\n",
    "args.train_size = 100 # if set to None -> train on full dataset\n",
    "args.val_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader classes / preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCQM4MV2_XYZ(InMemoryDataset):\n",
    "    r\"\"\"3D coordinates for molecules in the PCQM4Mv2 dataset (from zip).\n",
    "    \"\"\"\n",
    "\n",
    "    raw_url = 'http://ogb-data.stanford.edu/data/lsc/pcqm4m-v2_xyz.zip'\n",
    "\n",
    "    def __init__(self, root: str, transform: Optional[Callable] = None,\n",
    "                 pre_transform: Optional[Callable] = None,\n",
    "                 pre_filter: Optional[Callable] = None, dataset_arg: Optional[str] = None):\n",
    "        assert dataset_arg is None, \"PCQM4MV2 does not take any dataset args.\"\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return ['pcqm4m-v2_xyz']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'pcqm4mv2__xyz.pt'\n",
    "\n",
    "    def download(self):\n",
    "        file_path = download_url(self.raw_url, self.raw_dir)\n",
    "        extract_zip(file_path, self.raw_dir)\n",
    "        os.unlink(file_path)\n",
    "\n",
    "    def process(self):\n",
    "        dataset = PCQM4MV2_3D(self.raw_paths[0])\n",
    "        \n",
    "        data_list = []\n",
    "        for i, mol in enumerate(tqdm(dataset)):\n",
    "            pos = mol['coords']\n",
    "            pos = torch.tensor(pos, dtype=torch.float)\n",
    "            z = torch.tensor(mol['atom_type'], dtype=torch.long)\n",
    "\n",
    "            data = Data(z=z, pos=pos, idx=i)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            data_list.append(data)\n",
    "\n",
    "        torch.save(self.collate(data_list), self.processed_paths[0])\n",
    "\n",
    "class PCQM4MV2_3D:\n",
    "    \"\"\"Data loader for PCQM4MV2 from raw xyz files.\n",
    "    \n",
    "    Loads data given a path with .xyz files.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path) -> None:\n",
    "        self.path = path\n",
    "        self.xyz_files = glob.glob(path + '/*/*.xyz')\n",
    "        self.xyz_files = sorted(self.xyz_files, key=self._molecule_id_from_file)\n",
    "        self.num_molecules = len(self.xyz_files)\n",
    "        \n",
    "    def read_xyz_file(self, file_path):\n",
    "        atom_types = np.genfromtxt(file_path, skip_header=1, usecols=range(1), dtype=str)\n",
    "        atom_types = np.array([ase.Atom(sym).number for sym in atom_types])\n",
    "        atom_positions = np.genfromtxt(file_path, skip_header=1, usecols=range(1, 4), dtype=np.float32)        \n",
    "        return {'atom_type': atom_types, 'coords': atom_positions}\n",
    "    \n",
    "    def _molecule_id_from_file(self, file_path):\n",
    "        return int(os.path.splitext(os.path.basename(file_path))[0])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_molecules\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.read_xyz_file(self.xyz_files[idx])\n",
    "\n",
    "class DataModule(LightningDataModule):\n",
    "    def __init__(self, hparams, dataset=None):\n",
    "        super(DataModule, self).__init__()\n",
    "        self.hparams = hparams.__dict__ if hasattr(hparams, \"__dict__\") else hparams\n",
    "        self._mean, self._std = None, None\n",
    "        self._saved_dataloaders = dict()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if self.dataset is None:\n",
    "            if self.hparams['position_noise_scale'] > 0.:\n",
    "                def transform(data):\n",
    "                    noise = torch.randn_like(data.pos) * self.hparams['position_noise_scale']\n",
    "                    data.pos_target = noise\n",
    "                    data.pos = data.pos + noise\n",
    "                    return data\n",
    "            else:\n",
    "                transform = None\n",
    "            \n",
    "            # Noisy version of dataset\n",
    "            self.dataset_maybe_noisy = PCQM4MV2_XYZ(\n",
    "                self.hparams[\"dataset_root\"], \n",
    "                dataset_arg=self.hparams[\"dataset_arg\"], \n",
    "                transform = transform\n",
    "            )\n",
    "            \n",
    "            # Clean version of dataset\n",
    "            self.dataset = PCQM4MV2_XYZ(\n",
    "                self.hparams[\"dataset_root\"], \n",
    "                dataset_arg=self.hparams[\"dataset_arg\"], \n",
    "                transform = None\n",
    "            )\n",
    "\n",
    "        self.idx_train, self.idx_val, self.idx_test = make_splits(\n",
    "            len(self.dataset),\n",
    "            self.hparams[\"train_size\"],\n",
    "            self.hparams[\"val_size\"],\n",
    "            self.hparams[\"test_size\"],\n",
    "            self.hparams[\"seed\"],\n",
    "            join(self.hparams[\"log_dir\"], \"splits.npz\"),\n",
    "            self.hparams[\"splits\"],\n",
    "        )\n",
    "        print(\n",
    "            f\"train {len(self.idx_train)}, val {len(self.idx_val)}, test {len(self.idx_test)}\"\n",
    "        )\n",
    "\n",
    "        self.train_dataset = Subset(self.dataset_maybe_noisy, self.idx_train)\n",
    "\n",
    "        # If denoising is the only task, test/val datasets are also used for measuring denoising performance.\n",
    "        self.val_dataset = Subset(self.dataset_maybe_noisy, self.idx_val)\n",
    "        self.test_dataset = Subset(self.dataset_maybe_noisy, self.idx_test)            \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self._get_dataloader(self.train_dataset, \"train\")\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        loaders = [self._get_dataloader(self.val_dataset, \"val\")]\n",
    "        if (\n",
    "            len(self.test_dataset) > 0\n",
    "            and self.trainer.current_epoch % self.hparams[\"test_interval\"] == 0\n",
    "        ):\n",
    "            loaders.append(self._get_dataloader(self.test_dataset, \"test\"))\n",
    "        return loaders\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self._get_dataloader(self.test_dataset, \"test\")\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self._mean\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return self._std\n",
    "\n",
    "    def _get_dataloader(self, dataset, stage, store_dataloader=True):\n",
    "        store_dataloader = (\n",
    "            store_dataloader and not self.trainer.reload_dataloaders_every_epoch\n",
    "        )\n",
    "        if stage in self._saved_dataloaders and store_dataloader:\n",
    "            # storing the dataloaders like this breaks calls to trainer.reload_train_val_dataloaders\n",
    "            # but makes it possible that the dataloaders are not recreated on every testing epoch\n",
    "            return self._saved_dataloaders[stage]\n",
    "\n",
    "        if stage == \"train\":\n",
    "            batch_size = self.hparams[\"batch_size\"]\n",
    "            shuffle = True\n",
    "        elif stage in [\"val\", \"test\"]:\n",
    "            batch_size = self.hparams[\"inference_batch_size\"]\n",
    "            shuffle = False\n",
    "\n",
    "        dl = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=self.hparams[\"num_workers\"],\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        if store_dataloader:\n",
    "            self._saved_dataloaders[stage] = dl\n",
    "        return dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utilities\n",
    "def save_argparse(args, filename, exclude=None):\n",
    "    if filename.endswith(\"yaml\") or filename.endswith(\"yml\"):\n",
    "        if isinstance(exclude, str):\n",
    "            exclude = [exclude]\n",
    "        args = args.__dict__.copy()\n",
    "        for exl in exclude:\n",
    "            del args[exl]\n",
    "        yaml.dump(args, open(filename, \"w\"))\n",
    "    else:\n",
    "        raise ValueError(\"Configuration file should end with yaml or yml\")\n",
    "\n",
    "def number(text):\n",
    "    if text is None or text == \"None\":\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        num_int = int(text)\n",
    "    except ValueError:\n",
    "        num_int = None\n",
    "    num_float = float(text)\n",
    "\n",
    "    if num_int == num_float:\n",
    "        return num_int\n",
    "    return num_float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utilities for train / test split\n",
    "def make_splits(\n",
    "    dataset_len,\n",
    "    train_size,\n",
    "    val_size,\n",
    "    test_size,\n",
    "    seed,\n",
    "    filename=None,\n",
    "    splits=None,\n",
    "    order=None,\n",
    "):\n",
    "    if splits is not None:\n",
    "        splits = np.load(splits)\n",
    "        idx_train = splits[\"idx_train\"]\n",
    "        idx_val = splits[\"idx_val\"]\n",
    "        idx_test = splits[\"idx_test\"]\n",
    "    else:\n",
    "        idx_train, idx_val, idx_test = train_val_test_split(\n",
    "            dataset_len, train_size, val_size, test_size, seed, order\n",
    "        )\n",
    "\n",
    "    if filename is not None:\n",
    "        np.savez(filename, idx_train=idx_train, idx_val=idx_val, idx_test=idx_test)\n",
    "\n",
    "    return (\n",
    "        torch.from_numpy(idx_train),\n",
    "        torch.from_numpy(idx_val),\n",
    "        torch.from_numpy(idx_test),\n",
    "    )\n",
    "\n",
    "def train_val_test_split(dset_len, train_size, val_size, test_size, seed, order=None):\n",
    "    assert (train_size is None) + (val_size is None) + (\n",
    "        test_size is None\n",
    "    ) <= 1, \"Only one of train_size, val_size, test_size is allowed to be None.\"\n",
    "    is_float = (\n",
    "        isinstance(train_size, float),\n",
    "        isinstance(val_size, float),\n",
    "        isinstance(test_size, float),\n",
    "    )\n",
    "\n",
    "    train_size = round(dset_len * train_size) if is_float[0] else train_size\n",
    "    val_size = round(dset_len * val_size) if is_float[1] else val_size\n",
    "    test_size = round(dset_len * test_size) if is_float[2] else test_size\n",
    "\n",
    "    if train_size is None:\n",
    "        train_size = dset_len - val_size - test_size\n",
    "    elif val_size is None:\n",
    "        val_size = dset_len - train_size - test_size\n",
    "    elif test_size is None:\n",
    "        test_size = dset_len - train_size - val_size\n",
    "\n",
    "    if train_size + val_size + test_size > dset_len:\n",
    "        if is_float[2]:\n",
    "            test_size -= 1\n",
    "        elif is_float[1]:\n",
    "            val_size -= 1\n",
    "        elif is_float[0]:\n",
    "            train_size -= 1\n",
    "\n",
    "    assert train_size >= 0 and val_size >= 0 and test_size >= 0, (\n",
    "        f\"One of training ({train_size}), validation ({val_size}) or \"\n",
    "        f\"testing ({test_size}) splits ended up with a negative size.\"\n",
    "    )\n",
    "\n",
    "    total = train_size + val_size + test_size\n",
    "    assert dset_len >= total, (\n",
    "        f\"The dataset ({dset_len}) is smaller than the \"\n",
    "        f\"combined split sizes ({total}).\"\n",
    "    )\n",
    "    if total < dset_len:\n",
    "        rank_zero_warn(f\"{dset_len - total} samples were excluded from the dataset\")\n",
    "\n",
    "    idxs = np.arange(dset_len, dtype=np.int)\n",
    "    if order is None:\n",
    "        idxs = np.random.default_rng(seed).permutation(idxs)\n",
    "\n",
    "    idx_train = idxs[:train_size]\n",
    "    idx_val = idxs[train_size : train_size + val_size]\n",
    "    idx_test = idxs[train_size + val_size : total]\n",
    "\n",
    "    if order is not None:\n",
    "        idx_train = [order[i] for i in idx_train]\n",
    "        idx_val = [order[i] for i in idx_val]\n",
    "        idx_test = [order[i] for i in idx_test]\n",
    "\n",
    "    return np.array(idx_train), np.array(idx_val), np.array(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model classes\n",
    "class LNNP(LightningModule):\n",
    "    def __init__(self, hparams, prior_model=None, mean=None, std=None):\n",
    "        super(LNNP, self).__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "\n",
    "        if self.hparams.load_model:\n",
    "            self.model = load_model(self.hparams.load_model, args=self.hparams)\n",
    "        elif self.hparams.pretrained_model:\n",
    "            self.model = load_model(self.hparams.pretrained_model, args=self.hparams, mean=mean, std=std)\n",
    "        else:\n",
    "            self.model = create_model(self.hparams, prior_model, mean, std)\n",
    "\n",
    "        # initialize exponential smoothing\n",
    "        self.ema = None\n",
    "        self._reset_ema_dict()\n",
    "\n",
    "        # initialize loss collection\n",
    "        self.losses = None\n",
    "        self._reset_losses_dict()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    "        if self.hparams.lr_schedule == 'cosine':\n",
    "            scheduler = CosineAnnealingLR(optimizer, self.hparams.lr_cosine_length)\n",
    "            lr_scheduler = {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1,\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown lr_schedule: {self.hparams.lr_schedule}\")\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def forward(self, z, pos, batch=None):\n",
    "        return self.model(z, pos, batch=batch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, mse_loss, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, *args):\n",
    "        if len(args) == 0 or (len(args) > 0 and args[0] == 0):\n",
    "            # validation step\n",
    "            return self.step(batch, mse_loss, \"val\")\n",
    "        # test step\n",
    "        return self.step(batch, l1_loss, \"test\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, l1_loss, \"test\")\n",
    "\n",
    "    def step(self, batch, loss_fn, stage):\n",
    "        with torch.set_grad_enabled(stage == \"train\" or self.hparams.derivative):\n",
    "            # TODO: the model doesn't necessarily need to return a derivative once\n",
    "            # Union typing works under TorchScript (https://github.com/pytorch/pytorch/pull/53180)\n",
    "            pred, noise_pred, deriv = self(batch.z, batch.pos, batch.batch)\n",
    "\n",
    "        denoising_is_on = (\"pos_target\" in batch) and (self.hparams.denoising_weight > 0) and (noise_pred is not None)\n",
    "\n",
    "        loss_y, loss_dy, loss_pos = 0, 0, 0\n",
    "        \n",
    "        if \"y\" in batch:\n",
    "            if (noise_pred is not None) and not denoising_is_on:\n",
    "                # \"use\" both outputs of the model's forward (see comment above).\n",
    "                pred = pred + noise_pred.sum() * 0\n",
    "\n",
    "            if batch.y.ndim == 1:\n",
    "                batch.y = batch.y.unsqueeze(1)\n",
    "\n",
    "            # energy/prediction loss\n",
    "            loss_y = loss_fn(pred, batch.y)\n",
    "\n",
    "            if stage in [\"train\", \"val\"] and self.hparams.ema_alpha_y < 1:\n",
    "                if self.ema[stage + \"_y\"] is None:\n",
    "                    self.ema[stage + \"_y\"] = loss_y.detach()\n",
    "                # apply exponential smoothing over batches to y\n",
    "                loss_y = (\n",
    "                    self.hparams.ema_alpha_y * loss_y\n",
    "                    + (1 - self.hparams.ema_alpha_y) * self.ema[stage + \"_y\"]\n",
    "                )\n",
    "                self.ema[stage + \"_y\"] = loss_y.detach()\n",
    "\n",
    "            if self.hparams.energy_weight > 0:\n",
    "                self.losses[stage + \"_y\"].append(loss_y.detach())\n",
    "\n",
    "        if denoising_is_on:\n",
    "            if \"y\" not in batch:\n",
    "                # \"use\" both outputs of the model's forward (see comment above).\n",
    "                noise_pred = noise_pred + pred.sum() * 0\n",
    "                \n",
    "            normalized_pos_target = self.model.pos_normalizer(batch.pos_target)\n",
    "            loss_pos = loss_fn(noise_pred, normalized_pos_target)\n",
    "            self.losses[stage + \"_pos\"].append(loss_pos.detach())\n",
    "\n",
    "        # total loss\n",
    "        loss = loss_y * self.hparams.energy_weight + loss_dy * self.hparams.force_weight + loss_pos * self.hparams.denoising_weight\n",
    "\n",
    "        self.losses[stage].append(loss.detach())\n",
    "\n",
    "        # Frequent per-batch logging for training\n",
    "        if stage == 'train':\n",
    "            train_metrics = {k + \"_per_step\": v[-1] for k, v in self.losses.items() if (k.startswith(\"train\") and len(v) > 0)}\n",
    "            train_metrics['lr_per_step'] = self.trainer.optimizers[0].param_groups[0][\"lr\"]\n",
    "            train_metrics['step'] = self.trainer.global_step   \n",
    "            train_metrics['batch_pos_mean'] = batch.pos.mean().item()\n",
    "            self.log_dict(train_metrics, sync_dist=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def optimizer_step(self, *args, **kwargs):\n",
    "        optimizer = kwargs[\"optimizer\"] if \"optimizer\" in kwargs else args[2]\n",
    "        if self.trainer.global_step < self.hparams.lr_warmup_steps:\n",
    "            lr_scale = min(\n",
    "                1.0,\n",
    "                float(self.trainer.global_step + 1)\n",
    "                / float(self.hparams.lr_warmup_steps),\n",
    "            )\n",
    "\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg[\"lr\"] = lr_scale * self.hparams.lr\n",
    "        super().optimizer_step(*args, **kwargs)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        dm = self.trainer.datamodule\n",
    "        if hasattr(dm, \"test_dataset\") and len(dm.test_dataset) > 0:\n",
    "            should_reset = (\n",
    "                self.current_epoch % self.hparams.test_interval == 0\n",
    "                or (self.current_epoch - 1) % self.hparams.test_interval == 0\n",
    "            )\n",
    "            if should_reset:\n",
    "                # reset validation dataloaders before and after testing epoch, which is faster\n",
    "                # than skipping test validation steps by returning None\n",
    "                self.trainer.reset_val_dataloader(self)\n",
    "\n",
    "    # TODO(shehzaidi): clean up this function, redundant logging if dy loss exists.\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        if not self.trainer.running_sanity_check:\n",
    "            # construct dict of logged metrics\n",
    "            result_dict = {\n",
    "                \"epoch\": self.current_epoch,\n",
    "                \"lr\": self.trainer.optimizers[0].param_groups[0][\"lr\"],\n",
    "                \"train_loss\": torch.stack(self.losses[\"train\"]).mean(),\n",
    "                \"val_loss\": torch.stack(self.losses[\"val\"]).mean(),\n",
    "            }\n",
    "\n",
    "            # add test loss if available\n",
    "            if len(self.losses[\"test\"]) > 0:\n",
    "                result_dict[\"test_loss\"] = torch.stack(self.losses[\"test\"]).mean()\n",
    "\n",
    "            # if prediction and derivative are present, also log them separately\n",
    "            if len(self.losses[\"train_y\"]) > 0 and len(self.losses[\"train_dy\"]) > 0:\n",
    "                result_dict[\"train_loss_y\"] = torch.stack(self.losses[\"train_y\"]).mean()\n",
    "                result_dict[\"train_loss_dy\"] = torch.stack(\n",
    "                    self.losses[\"train_dy\"]\n",
    "                ).mean()\n",
    "                result_dict[\"val_loss_y\"] = torch.stack(self.losses[\"val_y\"]).mean()\n",
    "                result_dict[\"val_loss_dy\"] = torch.stack(self.losses[\"val_dy\"]).mean()\n",
    "\n",
    "                if len(self.losses[\"test\"]) > 0:\n",
    "                    result_dict[\"test_loss_y\"] = torch.stack(\n",
    "                        self.losses[\"test_y\"]\n",
    "                    ).mean()\n",
    "                    result_dict[\"test_loss_dy\"] = torch.stack(\n",
    "                        self.losses[\"test_dy\"]\n",
    "                    ).mean()\n",
    "\n",
    "            if len(self.losses[\"train_y\"]) > 0:\n",
    "                result_dict[\"train_loss_y\"] = torch.stack(self.losses[\"train_y\"]).mean()\n",
    "            if len(self.losses['val_y']) > 0:\n",
    "              result_dict[\"val_loss_y\"] = torch.stack(self.losses[\"val_y\"]).mean()\n",
    "            if len(self.losses[\"test_y\"]) > 0:\n",
    "                result_dict[\"test_loss_y\"] = torch.stack(\n",
    "                    self.losses[\"test_y\"]\n",
    "                ).mean()\n",
    "\n",
    "            # if denoising is present, also log it\n",
    "            if len(self.losses[\"train_pos\"]) > 0:\n",
    "                result_dict[\"train_loss_pos\"] = torch.stack(\n",
    "                    self.losses[\"train_pos\"]\n",
    "                ).mean()\n",
    "\n",
    "            if len(self.losses[\"val_pos\"]) > 0:\n",
    "                result_dict[\"val_loss_pos\"] = torch.stack(\n",
    "                    self.losses[\"val_pos\"]\n",
    "                ).mean()\n",
    "\n",
    "            if len(self.losses[\"test_pos\"]) > 0:\n",
    "                result_dict[\"test_loss_pos\"] = torch.stack(\n",
    "                    self.losses[\"test_pos\"]\n",
    "                ).mean()\n",
    "\n",
    "            self.log_dict(result_dict, sync_dist=True)\n",
    "        self._reset_losses_dict()\n",
    "\n",
    "    def _reset_losses_dict(self):\n",
    "        self.losses = {\n",
    "            \"train\": [],\n",
    "            \"val\": [],\n",
    "            \"test\": [],\n",
    "            \"train_y\": [],\n",
    "            \"val_y\": [],\n",
    "            \"test_y\": [],\n",
    "            \"train_dy\": [],\n",
    "            \"val_dy\": [],\n",
    "            \"test_dy\": [],\n",
    "            \"train_pos\": [],\n",
    "            \"val_pos\": [],\n",
    "            \"test_pos\": [],\n",
    "        }\n",
    "\n",
    "    def _reset_ema_dict(self):\n",
    "        self.ema = {\"train_y\": None, \"val_y\": None, \"train_dy\": None, \"val_dy\": None}\n",
    "\n",
    "class TorchMD_Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        representation_model,\n",
    "        output_model,\n",
    "        prior_model=None,\n",
    "        reduce_op=\"add\",\n",
    "        mean=None,\n",
    "        std=None,\n",
    "        derivative=False,\n",
    "        output_model_noise=None,\n",
    "        position_noise_scale=0.,\n",
    "    ):\n",
    "        super(TorchMD_Net, self).__init__()\n",
    "        self.representation_model = representation_model\n",
    "        self.output_model = output_model\n",
    "\n",
    "        self.prior_model = prior_model\n",
    "        if not output_model.allow_prior_model and prior_model is not None:\n",
    "            self.prior_model = None\n",
    "            rank_zero_warn(\n",
    "                (\n",
    "                    \"Prior model was given but the output model does \"\n",
    "                    \"not allow prior models. Dropping the prior model.\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.reduce_op = reduce_op\n",
    "        self.derivative = derivative\n",
    "        self.output_model_noise = output_model_noise        \n",
    "        self.position_noise_scale = position_noise_scale\n",
    "\n",
    "        mean = torch.scalar_tensor(0) if mean is None else mean\n",
    "        self.register_buffer(\"mean\", mean)\n",
    "        std = torch.scalar_tensor(1) if std is None else std\n",
    "        self.register_buffer(\"std\", std)\n",
    "\n",
    "        if self.position_noise_scale > 0:\n",
    "            self.pos_normalizer = AccumulatedNormalization(accumulator_shape=(3,))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.representation_model.reset_parameters()\n",
    "        self.output_model.reset_parameters()\n",
    "        if self.prior_model is not None:\n",
    "            self.prior_model.reset_parameters()\n",
    "\n",
    "    def forward(self, z, pos, batch: Optional[torch.Tensor] = None):\n",
    "        assert z.dim() == 1 and z.dtype == torch.long\n",
    "        batch = torch.zeros_like(z) if batch is None else batch\n",
    "\n",
    "        # run the potentially wrapped representation model\n",
    "        x, v, z, pos, batch = self.representation_model(z, pos, batch=batch)\n",
    "\n",
    "        # predict noise\n",
    "        noise_pred = None\n",
    "        if self.output_model_noise is not None:\n",
    "            noise_pred = self.output_model_noise.pre_reduce(x, v, z, pos, batch) \n",
    "\n",
    "        # apply the output network\n",
    "        x = self.output_model.pre_reduce(x, v, z, pos, batch)\n",
    "\n",
    "        # scale by data standard deviation\n",
    "        if self.std is not None:\n",
    "            x = x * self.std\n",
    "\n",
    "        # apply prior model\n",
    "        if self.prior_model is not None:\n",
    "            x = self.prior_model(x, z, pos, batch)\n",
    "\n",
    "        # aggregate atoms\n",
    "        out = scatter(x, batch, dim=0, reduce=self.reduce_op)\n",
    "\n",
    "        # shift by data mean\n",
    "        if self.mean is not None:\n",
    "            out = out + self.mean\n",
    "\n",
    "        # apply output model after reduction\n",
    "        out = self.output_model.post_reduce(out)\n",
    "\n",
    "        return out, noise_pred, None\n",
    "\n",
    "class TorchMD_ET(nn.Module):\n",
    "    r\"\"\"The TorchMD equivariant Transformer architecture.\n",
    "\n",
    "    Args:\n",
    "        hidden_channels (int, optional): Hidden embedding size.\n",
    "            (default: :obj:`128`)\n",
    "        num_layers (int, optional): The number of attention layers.\n",
    "            (default: :obj:`6`)\n",
    "        num_rbf (int, optional): The number of radial basis functions :math:`\\mu`.\n",
    "            (default: :obj:`50`)\n",
    "        rbf_type (string, optional): The type of radial basis function to use.\n",
    "            (default: :obj:`\"expnorm\"`)\n",
    "        trainable_rbf (bool, optional): Whether to train RBF parameters with\n",
    "            backpropagation. (default: :obj:`True`)\n",
    "        activation (string, optional): The type of activation function to use.\n",
    "            (default: :obj:`\"silu\"`)\n",
    "        attn_activation (string, optional): The type of activation function to use\n",
    "            inside the attention mechanism. (default: :obj:`\"silu\"`)\n",
    "        neighbor_embedding (bool, optional): Whether to perform an initial neighbor\n",
    "            embedding step. (default: :obj:`True`)\n",
    "        num_heads (int, optional): Number of attention heads.\n",
    "            (default: :obj:`8`)\n",
    "        distance_influence (string, optional): Where distance information is used inside\n",
    "            the attention mechanism. (default: :obj:`\"both\"`)\n",
    "        cutoff_lower (float, optional): Lower cutoff distance for interatomic interactions.\n",
    "            (default: :obj:`0.0`)\n",
    "        cutoff_upper (float, optional): Upper cutoff distance for interatomic interactions.\n",
    "            (default: :obj:`5.0`)\n",
    "        max_z (int, optional): Maximum atomic number. Used for initializing embeddings.\n",
    "            (default: :obj:`100`)\n",
    "        max_num_neighbors (int, optional): Maximum number of neighbors to return for a\n",
    "            given node/atom when constructing the molecular graph during forward passes.\n",
    "            This attribute is passed to the torch_cluster radius_graph routine keyword\n",
    "            max_num_neighbors, which normally defaults to 32. Users should set this to\n",
    "            higher values if they are using higher upper distance cutoffs and expect more\n",
    "            than 32 neighbors per node/atom.\n",
    "            (default: :obj:`32`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels=128,\n",
    "        num_layers=6,\n",
    "        num_rbf=50,\n",
    "        rbf_type=\"expnorm\",\n",
    "        trainable_rbf=True,\n",
    "        activation=\"silu\",\n",
    "        attn_activation=\"silu\",\n",
    "        neighbor_embedding=True,\n",
    "        num_heads=8,\n",
    "        distance_influence=\"both\",\n",
    "        cutoff_lower=0.0,\n",
    "        cutoff_upper=5.0,\n",
    "        max_z=100,\n",
    "        max_num_neighbors=32,\n",
    "        layernorm_on_vec=None,\n",
    "    ):\n",
    "        super(TorchMD_ET, self).__init__()\n",
    "\n",
    "        assert distance_influence in [\"keys\", \"values\", \"both\", \"none\"]\n",
    "        assert rbf_type in rbf_class_mapping, (\n",
    "            f'Unknown RBF type \"{rbf_type}\". '\n",
    "            f'Choose from {\", \".join(rbf_class_mapping.keys())}.'\n",
    "        )\n",
    "        assert activation in act_class_mapping, (\n",
    "            f'Unknown activation function \"{activation}\". '\n",
    "            f'Choose from {\", \".join(act_class_mapping.keys())}.'\n",
    "        )\n",
    "        assert attn_activation in act_class_mapping, (\n",
    "            f'Unknown attention activation function \"{attn_activation}\". '\n",
    "            f'Choose from {\", \".join(act_class_mapping.keys())}.'\n",
    "        )\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.num_rbf = num_rbf\n",
    "        self.rbf_type = rbf_type\n",
    "        self.trainable_rbf = trainable_rbf\n",
    "        self.activation = activation\n",
    "        self.attn_activation = attn_activation\n",
    "        self.neighbor_embedding = neighbor_embedding\n",
    "        self.num_heads = num_heads\n",
    "        self.distance_influence = distance_influence\n",
    "        self.cutoff_lower = cutoff_lower\n",
    "        self.cutoff_upper = cutoff_upper\n",
    "        self.max_z = max_z\n",
    "        self.layernorm_on_vec = layernorm_on_vec\n",
    "\n",
    "        act_class = act_class_mapping[activation]\n",
    "\n",
    "        self.embedding = nn.Embedding(self.max_z, hidden_channels)\n",
    "\n",
    "        self.distance = Distance(\n",
    "            cutoff_lower,\n",
    "            cutoff_upper,\n",
    "            max_num_neighbors=max_num_neighbors,\n",
    "            return_vecs=True,\n",
    "            loop=True,\n",
    "        )\n",
    "        self.distance_expansion = rbf_class_mapping[rbf_type](\n",
    "            cutoff_lower, cutoff_upper, num_rbf, trainable_rbf\n",
    "        )\n",
    "        self.neighbor_embedding = (\n",
    "            NeighborEmbedding(\n",
    "                hidden_channels, num_rbf, cutoff_lower, cutoff_upper, self.max_z\n",
    "            ).jittable()\n",
    "            if neighbor_embedding\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.attention_layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            layer = EquivariantMultiHeadAttention(\n",
    "                hidden_channels,\n",
    "                num_rbf,\n",
    "                distance_influence,\n",
    "                num_heads,\n",
    "                act_class,\n",
    "                attn_activation,\n",
    "                cutoff_lower,\n",
    "                cutoff_upper,\n",
    "            ).jittable()\n",
    "            self.attention_layers.append(layer)\n",
    "\n",
    "        self.out_norm = nn.LayerNorm(hidden_channels)\n",
    "        if self.layernorm_on_vec:\n",
    "            if self.layernorm_on_vec == \"whitened\":\n",
    "                self.out_norm_vec = EquivariantLayerNorm(hidden_channels)\n",
    "            else:\n",
    "                raise ValueError(f\"{self.layernorm_on_vec} not recognized.\")\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embedding.reset_parameters()\n",
    "        self.distance_expansion.reset_parameters()\n",
    "        if self.neighbor_embedding is not None:\n",
    "            self.neighbor_embedding.reset_parameters()\n",
    "        for attn in self.attention_layers:\n",
    "            attn.reset_parameters()\n",
    "        self.out_norm.reset_parameters()\n",
    "        if self.layernorm_on_vec:\n",
    "            self.out_norm_vec.reset_parameters()\n",
    "\n",
    "    def forward(self, z, pos, batch):\n",
    "        x = self.embedding(z)\n",
    "\n",
    "        edge_index, edge_weight, edge_vec = self.distance(pos, batch)\n",
    "        assert (\n",
    "            edge_vec is not None\n",
    "        ), \"Distance module did not return directional information\"\n",
    "\n",
    "        edge_attr = self.distance_expansion(edge_weight)\n",
    "        mask = edge_index[0] != edge_index[1]\n",
    "        edge_vec[mask] = edge_vec[mask] / torch.norm(edge_vec[mask], dim=1).unsqueeze(1)\n",
    "\n",
    "        if self.neighbor_embedding is not None:\n",
    "            x = self.neighbor_embedding(z, x, edge_index, edge_weight, edge_attr)\n",
    "\n",
    "        vec = torch.zeros(x.size(0), 3, x.size(1), device=x.device)\n",
    "\n",
    "        for attn in self.attention_layers:\n",
    "            dx, dvec = attn(x, vec, edge_index, edge_weight, edge_attr, edge_vec)\n",
    "            x = x + dx\n",
    "            vec = vec + dvec\n",
    "        x = self.out_norm(x)\n",
    "        if self.layernorm_on_vec:\n",
    "            vec = self.out_norm_vec(vec)\n",
    "\n",
    "        return x, vec, z, pos, batch\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(\"\n",
    "            f\"hidden_channels={self.hidden_channels}, \"\n",
    "            f\"num_layers={self.num_layers}, \"\n",
    "            f\"num_rbf={self.num_rbf}, \"\n",
    "            f\"rbf_type={self.rbf_type}, \"\n",
    "            f\"trainable_rbf={self.trainable_rbf}, \"\n",
    "            f\"activation={self.activation}, \"\n",
    "            f\"attn_activation={self.attn_activation}, \"\n",
    "            f\"neighbor_embedding={self.neighbor_embedding}, \"\n",
    "            f\"num_heads={self.num_heads}, \"\n",
    "            f\"distance_influence={self.distance_influence}, \"\n",
    "            f\"cutoff_lower={self.cutoff_lower}, \"\n",
    "            f\"cutoff_upper={self.cutoff_upper})\"\n",
    "        )\n",
    "\n",
    "class OutputModel(nn.Module, metaclass=ABCMeta):\n",
    "    def __init__(self, allow_prior_model):\n",
    "        super(OutputModel, self).__init__()\n",
    "        self.allow_prior_model = allow_prior_model\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def pre_reduce(self, x, v, z, pos, batch):\n",
    "        return\n",
    "\n",
    "    def post_reduce(self, x):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model utilities\n",
    "class Distance(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cutoff_lower,\n",
    "        cutoff_upper,\n",
    "        max_num_neighbors=32,\n",
    "        return_vecs=False,\n",
    "        loop=False,\n",
    "    ):\n",
    "        super(Distance, self).__init__()\n",
    "        self.cutoff_lower = cutoff_lower\n",
    "        self.cutoff_upper = cutoff_upper\n",
    "        self.max_num_neighbors = max_num_neighbors\n",
    "        self.return_vecs = return_vecs\n",
    "        self.loop = loop\n",
    "\n",
    "    def forward(self, pos, batch):\n",
    "        edge_index = radius_graph(\n",
    "            pos,\n",
    "            r=self.cutoff_upper,\n",
    "            batch=batch,\n",
    "            loop=self.loop,\n",
    "            max_num_neighbors=self.max_num_neighbors,\n",
    "        )\n",
    "        edge_vec = pos[edge_index[0]] - pos[edge_index[1]]\n",
    "\n",
    "        if self.loop:\n",
    "            # mask out self loops when computing distances because\n",
    "            # the norm of 0 produces NaN gradients\n",
    "            # NOTE: might influence force predictions as self loop gradients are ignored\n",
    "            mask = edge_index[0] != edge_index[1]\n",
    "            edge_weight = torch.zeros(edge_vec.size(0), device=edge_vec.device)\n",
    "            edge_weight[mask] = torch.norm(edge_vec[mask], dim=-1)\n",
    "        else:\n",
    "            edge_weight = torch.norm(edge_vec, dim=-1)\n",
    "\n",
    "        lower_mask = edge_weight >= self.cutoff_lower\n",
    "        edge_index = edge_index[:, lower_mask]\n",
    "        edge_weight = edge_weight[lower_mask]\n",
    "\n",
    "        if self.return_vecs:\n",
    "            edge_vec = edge_vec[lower_mask]\n",
    "            return edge_index, edge_weight, edge_vec\n",
    "        # TODO: return only `edge_index` and `edge_weight` once\n",
    "        # Union typing works with TorchScript (https://github.com/pytorch/pytorch/pull/53180)\n",
    "        return edge_index, edge_weight, None\n",
    "\n",
    "class CosineCutoff(nn.Module):\n",
    "    def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0):\n",
    "        super(CosineCutoff, self).__init__()\n",
    "        self.cutoff_lower = cutoff_lower\n",
    "        self.cutoff_upper = cutoff_upper\n",
    "\n",
    "    def forward(self, distances):\n",
    "        if self.cutoff_lower > 0:\n",
    "            cutoffs = 0.5 * (\n",
    "                torch.cos(\n",
    "                    math.pi\n",
    "                    * (\n",
    "                        2\n",
    "                        * (distances - self.cutoff_lower)\n",
    "                        / (self.cutoff_upper - self.cutoff_lower)\n",
    "                        + 1.0\n",
    "                    )\n",
    "                )\n",
    "                + 1.0\n",
    "            )\n",
    "            # remove contributions below the cutoff radius\n",
    "            cutoffs = cutoffs * (distances < self.cutoff_upper).float()\n",
    "            cutoffs = cutoffs * (distances > self.cutoff_lower).float()\n",
    "            return cutoffs\n",
    "        else:\n",
    "            cutoffs = 0.5 * (torch.cos(distances * math.pi / self.cutoff_upper) + 1.0)\n",
    "            # remove contributions beyond the cutoff radius\n",
    "            cutoffs = cutoffs * (distances < self.cutoff_upper).float()\n",
    "            return cutoffs\n",
    "\n",
    "class EquivariantMultiHeadAttention(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels,\n",
    "        num_rbf,\n",
    "        distance_influence,\n",
    "        num_heads,\n",
    "        activation,\n",
    "        attn_activation,\n",
    "        cutoff_lower,\n",
    "        cutoff_upper,\n",
    "    ):\n",
    "        super(EquivariantMultiHeadAttention, self).__init__(aggr=\"add\", node_dim=0)\n",
    "        assert hidden_channels % num_heads == 0, (\n",
    "            f\"The number of hidden channels ({hidden_channels}) \"\n",
    "            f\"must be evenly divisible by the number of \"\n",
    "            f\"attention heads ({num_heads})\"\n",
    "        )\n",
    "\n",
    "        self.distance_influence = distance_influence\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.head_dim = hidden_channels // num_heads\n",
    "\n",
    "        self.layernorm = nn.LayerNorm(hidden_channels)\n",
    "        self.act = activation()\n",
    "        self.attn_activation = act_class_mapping[attn_activation]()\n",
    "        self.cutoff = CosineCutoff(cutoff_lower, cutoff_upper)\n",
    "\n",
    "        self.q_proj = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.k_proj = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.v_proj = nn.Linear(hidden_channels, hidden_channels * 3)\n",
    "        self.o_proj = nn.Linear(hidden_channels, hidden_channels * 3)\n",
    "\n",
    "        self.vec_proj = nn.Linear(hidden_channels, hidden_channels * 3, bias=False)\n",
    "\n",
    "        self.dk_proj = None\n",
    "        if distance_influence in [\"keys\", \"both\"]:\n",
    "            self.dk_proj = nn.Linear(num_rbf, hidden_channels)\n",
    "\n",
    "        self.dv_proj = None\n",
    "        if distance_influence in [\"values\", \"both\"]:\n",
    "            self.dv_proj = nn.Linear(num_rbf, hidden_channels * 3)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.layernorm.reset_parameters()\n",
    "        nn.init.xavier_uniform_(self.q_proj.weight)\n",
    "        self.q_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.k_proj.weight)\n",
    "        self.k_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.v_proj.weight)\n",
    "        self.v_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
    "        self.o_proj.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.vec_proj.weight)\n",
    "        if self.dk_proj:\n",
    "            nn.init.xavier_uniform_(self.dk_proj.weight)\n",
    "            self.dk_proj.bias.data.fill_(0)\n",
    "        if self.dv_proj:\n",
    "            nn.init.xavier_uniform_(self.dv_proj.weight)\n",
    "            self.dv_proj.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, vec, edge_index, r_ij, f_ij, d_ij):\n",
    "        x = self.layernorm(x)\n",
    "        q = self.q_proj(x).reshape(-1, self.num_heads, self.head_dim)\n",
    "        k = self.k_proj(x).reshape(-1, self.num_heads, self.head_dim)\n",
    "        v = self.v_proj(x).reshape(-1, self.num_heads, self.head_dim * 3)\n",
    "\n",
    "        vec1, vec2, vec3 = torch.split(self.vec_proj(vec), self.hidden_channels, dim=-1)\n",
    "        vec = vec.reshape(-1, 3, self.num_heads, self.head_dim)\n",
    "        vec_dot = (vec1 * vec2).sum(dim=1)\n",
    "\n",
    "        dk = (\n",
    "            self.act(self.dk_proj(f_ij)).reshape(-1, self.num_heads, self.head_dim)\n",
    "            if self.dk_proj is not None\n",
    "            else None\n",
    "        )\n",
    "        dv = (\n",
    "            self.act(self.dv_proj(f_ij)).reshape(-1, self.num_heads, self.head_dim * 3)\n",
    "            if self.dv_proj is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        # propagate_type: (q: Tensor, k: Tensor, v: Tensor, vec: Tensor, dk: Tensor, dv: Tensor, r_ij: Tensor, d_ij: Tensor)\n",
    "        x, vec = self.propagate(\n",
    "            edge_index,\n",
    "            q=q,\n",
    "            k=k,\n",
    "            v=v,\n",
    "            vec=vec,\n",
    "            dk=dk,\n",
    "            dv=dv,\n",
    "            r_ij=r_ij,\n",
    "            d_ij=d_ij,\n",
    "            size=None,\n",
    "        )\n",
    "        x = x.reshape(-1, self.hidden_channels)\n",
    "        vec = vec.reshape(-1, 3, self.hidden_channels)\n",
    "\n",
    "        o1, o2, o3 = torch.split(self.o_proj(x), self.hidden_channels, dim=1)\n",
    "        dx = vec_dot * o2 + o3\n",
    "        dvec = vec3 * o1.unsqueeze(1) + vec\n",
    "        return dx, dvec\n",
    "\n",
    "    def message(self, q_i, k_j, v_j, vec_j, dk, dv, r_ij, d_ij):\n",
    "        # attention mechanism\n",
    "        if dk is None:\n",
    "            attn = (q_i * k_j).sum(dim=-1)\n",
    "        else:\n",
    "            attn = (q_i * k_j * dk).sum(dim=-1)\n",
    "\n",
    "        # attention activation function\n",
    "        attn = self.attn_activation(attn) * self.cutoff(r_ij).unsqueeze(1)\n",
    "\n",
    "        # value pathway\n",
    "        if dv is not None:\n",
    "            v_j = v_j * dv\n",
    "        x, vec1, vec2 = torch.split(v_j, self.head_dim, dim=2)\n",
    "\n",
    "        # update scalar features\n",
    "        x = x * attn.unsqueeze(2)\n",
    "        # update vector features\n",
    "        vec = vec_j * vec1.unsqueeze(1) + vec2.unsqueeze(1) * d_ij.unsqueeze(\n",
    "            2\n",
    "        ).unsqueeze(3)\n",
    "        return x, vec\n",
    "\n",
    "    def aggregate(\n",
    "        self,\n",
    "        features: Tuple[torch.Tensor, torch.Tensor],\n",
    "        index: torch.Tensor,\n",
    "        ptr: Optional[torch.Tensor],\n",
    "        dim_size: Optional[int],\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x, vec = features\n",
    "        x = scatter(x, index, dim=self.node_dim, dim_size=dim_size)\n",
    "        vec = scatter(vec, index, dim=self.node_dim, dim_size=dim_size)\n",
    "        return x, vec\n",
    "\n",
    "    def update(\n",
    "        self, inputs: Tuple[torch.Tensor, torch.Tensor]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return inputs\n",
    "\n",
    "class EquivariantLayerNorm(nn.Module):\n",
    "    r\"\"\"Rotationally-equivariant Vector Layer Normalization\n",
    "    Expects inputs with shape (N, n, d), where N is batch size, n is vector dimension, d is width/number of vectors.\n",
    "    \"\"\"\n",
    "    __constants__ = [\"normalized_shape\", \"elementwise_linear\"]\n",
    "    normalized_shape: Tuple[int, ...]\n",
    "    eps: float\n",
    "    elementwise_linear: bool\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        normalized_shape: int,\n",
    "        eps: float = 1e-5,\n",
    "        elementwise_linear: bool = True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ) -> None:\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super(EquivariantLayerNorm, self).__init__()\n",
    "\n",
    "        self.normalized_shape = (int(normalized_shape),)\n",
    "        self.eps = eps\n",
    "        self.elementwise_linear = elementwise_linear\n",
    "        if self.elementwise_linear:\n",
    "            self.weight = Parameter(\n",
    "                torch.empty(self.normalized_shape, **factory_kwargs)\n",
    "            )\n",
    "        else:\n",
    "            self.register_parameter(\"weight\", None) # Without bias term to preserve equivariance!\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        if self.elementwise_linear:\n",
    "            nn.init.ones_(self.weight)\n",
    "\n",
    "    def mean_center(self, input):\n",
    "        return input - input.mean(-1, keepdim=True)\n",
    "\n",
    "    def covariance(self, input):\n",
    "        return 1 / self.normalized_shape[0] * input @ input.transpose(-1, -2)\n",
    "\n",
    "    def symsqrtinv(self, matrix):\n",
    "        \"\"\"Compute the inverse square root of a positive definite matrix.\n",
    "\n",
    "        Based on https://github.com/pytorch/pytorch/issues/25481\n",
    "        \"\"\"\n",
    "        _, s, v = matrix.svd()\n",
    "        good = (\n",
    "            s > s.max(-1, True).values * s.size(-1) * torch.finfo(s.dtype).eps\n",
    "        )\n",
    "        components = good.sum(-1)\n",
    "        common = components.max()\n",
    "        unbalanced = common != components.min()\n",
    "        if common < s.size(-1):\n",
    "            s = s[..., :common]\n",
    "            v = v[..., :common]\n",
    "            if unbalanced:\n",
    "                good = good[..., :common]\n",
    "        if unbalanced:\n",
    "            s = s.where(good, torch.zeros((), device=s.device, dtype=s.dtype))\n",
    "        return (v * 1 / torch.sqrt(s + self.eps).unsqueeze(-2)) @ v.transpose(\n",
    "            -2, -1\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        input = input.to(torch.float64) # Need double precision for accurate inversion.\n",
    "        input = self.mean_center(input)\n",
    "        # We use different diagonal elements in case input matrix is approximately zero,\n",
    "        # in which case all singular values are equal which is problematic for backprop.\n",
    "        # See e.g. https://pytorch.org/docs/stable/generated/torch.svd.html\n",
    "        reg_matrix = (\n",
    "            torch.diag(torch.tensor([1.0, 2.0, 3.0]))\n",
    "            .unsqueeze(0)\n",
    "            .to(input.device)\n",
    "            .type(input.dtype)\n",
    "        )\n",
    "        covar = self.covariance(input) + self.eps * reg_matrix\n",
    "        covar_sqrtinv = self.symsqrtinv(covar)\n",
    "        return (covar_sqrtinv @ input).to(\n",
    "            self.weight.dtype\n",
    "        ) * self.weight.reshape(1, 1, self.normalized_shape[0])\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return (\n",
    "            \"{normalized_shape}, \"\n",
    "            \"elementwise_linear={elementwise_linear}\".format(**self.__dict__)\n",
    "        )\n",
    "\n",
    "class AccumulatedNormalization(nn.Module):\n",
    "    \"\"\"Running normalization of a tensor.\"\"\"\n",
    "    def __init__(self, accumulator_shape: Tuple[int, ...], epsilon: float = 1e-8):\n",
    "        super(AccumulatedNormalization, self).__init__()\n",
    "\n",
    "        self._epsilon = epsilon\n",
    "        self.register_buffer(\"acc_sum\", torch.zeros(accumulator_shape))\n",
    "        self.register_buffer(\"acc_squared_sum\", torch.zeros(accumulator_shape))\n",
    "        self.register_buffer(\"acc_count\", torch.zeros((1,)))\n",
    "        self.register_buffer(\"num_accumulations\", torch.zeros((1,)))\n",
    "\n",
    "    def update_statistics(self, batch: torch.Tensor):\n",
    "        batch_size = batch.shape[0]\n",
    "        self.acc_sum += batch.sum(dim=0)\n",
    "        self.acc_squared_sum += batch.pow(2).sum(dim=0)\n",
    "        self.acc_count += batch_size\n",
    "        self.num_accumulations += 1\n",
    "\n",
    "    @property\n",
    "    def acc_count_safe(self):\n",
    "        return self.acc_count.clamp(min=1)\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.acc_sum / self.acc_count_safe\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return torch.sqrt(\n",
    "            (self.acc_squared_sum / self.acc_count_safe) - self.mean.pow(2)\n",
    "        ).clamp(min=self._epsilon)\n",
    "\n",
    "    def forward(self, batch: torch.Tensor):\n",
    "        if self.training:\n",
    "            self.update_statistics(batch)\n",
    "        return ((batch - self.mean) / self.std)\n",
    "\n",
    "class NeighborEmbedding(MessagePassing):\n",
    "    def __init__(self, hidden_channels, num_rbf, cutoff_lower, cutoff_upper, max_z=100):\n",
    "        super(NeighborEmbedding, self).__init__(aggr=\"add\")\n",
    "        self.embedding = nn.Embedding(max_z, hidden_channels)\n",
    "        self.distance_proj = nn.Linear(num_rbf, hidden_channels)\n",
    "        self.combine = nn.Linear(hidden_channels * 2, hidden_channels)\n",
    "        self.cutoff = CosineCutoff(cutoff_lower, cutoff_upper)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embedding.reset_parameters()\n",
    "        nn.init.xavier_uniform_(self.distance_proj.weight)\n",
    "        nn.init.xavier_uniform_(self.combine.weight)\n",
    "        self.distance_proj.bias.data.fill_(0)\n",
    "        self.combine.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, z, x, edge_index, edge_weight, edge_attr):\n",
    "        # remove self loops\n",
    "        mask = edge_index[0] != edge_index[1]\n",
    "        if not mask.all():\n",
    "            edge_index = edge_index[:, mask]\n",
    "            edge_weight = edge_weight[mask]\n",
    "            edge_attr = edge_attr[mask]\n",
    "\n",
    "        C = self.cutoff(edge_weight)\n",
    "        W = self.distance_proj(edge_attr) * C.view(-1, 1)\n",
    "\n",
    "        x_neighbors = self.embedding(z)\n",
    "        # propagate_type: (x: Tensor, W: Tensor)\n",
    "        x_neighbors = self.propagate(edge_index, x=x_neighbors, W=W, size=None)\n",
    "        x_neighbors = self.combine(torch.cat([x, x_neighbors], dim=1))\n",
    "        return x_neighbors\n",
    "\n",
    "    def message(self, x_j, W):\n",
    "        return x_j * W\n",
    "\n",
    "class ExpNormalSmearing(nn.Module):\n",
    "    def __init__(self, cutoff_lower=0.0, cutoff_upper=5.0, num_rbf=50, trainable=True):\n",
    "        super(ExpNormalSmearing, self).__init__()\n",
    "        self.cutoff_lower = cutoff_lower\n",
    "        self.cutoff_upper = cutoff_upper\n",
    "        self.num_rbf = num_rbf\n",
    "        self.trainable = trainable\n",
    "\n",
    "        self.cutoff_fn = CosineCutoff(0, cutoff_upper)\n",
    "        self.alpha = 5.0 / (cutoff_upper - cutoff_lower)\n",
    "\n",
    "        means, betas = self._initial_params()\n",
    "        if trainable:\n",
    "            self.register_parameter(\"means\", nn.Parameter(means))\n",
    "            self.register_parameter(\"betas\", nn.Parameter(betas))\n",
    "        else:\n",
    "            self.register_buffer(\"means\", means)\n",
    "            self.register_buffer(\"betas\", betas)\n",
    "\n",
    "    def _initial_params(self):\n",
    "        # initialize means and betas according to the default values in PhysNet\n",
    "        # https://pubs.acs.org/doi/10.1021/acs.jctc.9b00181\n",
    "        start_value = torch.exp(\n",
    "            torch.scalar_tensor(-self.cutoff_upper + self.cutoff_lower)\n",
    "        )\n",
    "        means = torch.linspace(start_value, 1, self.num_rbf)\n",
    "        betas = torch.tensor(\n",
    "            [(2 / self.num_rbf * (1 - start_value)) ** -2] * self.num_rbf\n",
    "        )\n",
    "        return means, betas\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        means, betas = self._initial_params()\n",
    "        self.means.data.copy_(means)\n",
    "        self.betas.data.copy_(betas)\n",
    "\n",
    "    def forward(self, dist):\n",
    "        dist = dist.unsqueeze(-1)\n",
    "        return self.cutoff_fn(dist) * torch.exp(\n",
    "            -self.betas\n",
    "            * (torch.exp(self.alpha * (-dist + self.cutoff_lower)) - self.means) ** 2\n",
    "        )\n",
    "\n",
    "class GatedEquivariantBlock(nn.Module):\n",
    "    \"\"\"Gated Equivariant Block as defined in Schtt et al. (2021):\n",
    "    Equivariant message passing for the prediction of tensorial properties and molecular spectra\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels,\n",
    "        out_channels,\n",
    "        intermediate_channels=None,\n",
    "        activation=\"silu\",\n",
    "        scalar_activation=False,\n",
    "    ):\n",
    "        super(GatedEquivariantBlock, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        if intermediate_channels is None:\n",
    "            intermediate_channels = hidden_channels\n",
    "\n",
    "        self.vec1_proj = nn.Linear(hidden_channels, hidden_channels, bias=False)\n",
    "        self.vec2_proj = nn.Linear(hidden_channels, out_channels, bias=False)\n",
    "\n",
    "        act_class = act_class_mapping[activation]\n",
    "        self.update_net = nn.Sequential(\n",
    "            nn.Linear(hidden_channels * 2, intermediate_channels),\n",
    "            act_class(),\n",
    "            nn.Linear(intermediate_channels, out_channels * 2),\n",
    "        )\n",
    "\n",
    "        self.act = act_class() if scalar_activation else None\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.vec1_proj.weight)\n",
    "        nn.init.xavier_uniform_(self.vec2_proj.weight)\n",
    "        nn.init.xavier_uniform_(self.update_net[0].weight)\n",
    "        self.update_net[0].bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.update_net[2].weight)\n",
    "        self.update_net[2].bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, v):\n",
    "        vec1 = torch.norm(self.vec1_proj(v), dim=-2)\n",
    "        vec2 = self.vec2_proj(v)\n",
    "\n",
    "        x = torch.cat([x, vec1], dim=-1)\n",
    "        x, v = torch.split(self.update_net(x), self.out_channels, dim=-1)\n",
    "        v = v.unsqueeze(1) * vec2\n",
    "\n",
    "        if self.act is not None:\n",
    "            x = self.act(x)\n",
    "        return x, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input mapping\n",
    "rbf_class_mapping = {\"expnorm\": ExpNormalSmearing}\n",
    "act_class_mapping = {\"silu\": nn.SiLU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create and load model\n",
    "def create_model(args, prior_model=None, mean=None, std=None):\n",
    "    shared_args = dict(\n",
    "        hidden_channels=args[\"embedding_dimension\"],\n",
    "        num_layers=args[\"num_layers\"],\n",
    "        num_rbf=args[\"num_rbf\"],\n",
    "        rbf_type=args[\"rbf_type\"],\n",
    "        trainable_rbf=args[\"trainable_rbf\"],\n",
    "        activation=args[\"activation\"],\n",
    "        neighbor_embedding=args[\"neighbor_embedding\"],\n",
    "        cutoff_lower=args[\"cutoff_lower\"],\n",
    "        cutoff_upper=args[\"cutoff_upper\"],\n",
    "        max_z=args[\"max_z\"],\n",
    "        max_num_neighbors=args[\"max_num_neighbors\"],\n",
    "    )\n",
    "\n",
    "    # representation network\n",
    "    if args[\"model\"] == \"equivariant-transformer\":\n",
    "        is_equivariant = True\n",
    "        representation_model = TorchMD_ET(\n",
    "            attn_activation=args[\"attn_activation\"],\n",
    "            num_heads=args[\"num_heads\"],\n",
    "            distance_influence=args[\"distance_influence\"],\n",
    "            layernorm_on_vec=args[\"layernorm_on_vec\"],\n",
    "            **shared_args,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Unknown architecture: {args[\"model\"]}')\n",
    "\n",
    "    # atom filter\n",
    "    representation_model = AtomFilter(representation_model, args[\"atom_filter\"])\n",
    "    \n",
    "    # create output network\n",
    "    output_model = EquivariantScalar(args[\"embedding_dimension\"], args[\"activation\"])\n",
    "\n",
    "    # create the denoising output network\n",
    "    output_model_noise = EquivariantVectorOutput(args[\"embedding_dimension\"], args[\"activation\"])\n",
    "    \n",
    "    # combine representation and output network\n",
    "    model = TorchMD_Net(\n",
    "        representation_model,\n",
    "        output_model,\n",
    "        prior_model=prior_model,\n",
    "        reduce_op=args[\"reduce_op\"],\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        derivative=args[\"derivative\"],\n",
    "        output_model_noise=output_model_noise,\n",
    "        position_noise_scale=args['position_noise_scale'],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def load_model(filepath, args=None, device=\"cpu\", mean=None, std=None, **kwargs):\n",
    "    ckpt = torch.load(filepath, map_location=\"cpu\")\n",
    "    if args is None:\n",
    "        args = ckpt[\"hyper_parameters\"]\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        if not key in args:\n",
    "            warnings.warn(f'Unknown hyperparameter: {key}={value}')\n",
    "        args[key] = value\n",
    "\n",
    "    model = create_model(args)\n",
    "\n",
    "    state_dict = {re.sub(r\"^model\\.\", \"\", k): v for k, v in ckpt[\"state_dict\"].items()}\n",
    "    loading_return = model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    if len(loading_return.unexpected_keys) > 0:\n",
    "        # Should only happen if not applying denoising during fine-tuning.\n",
    "        assert all((\"output_model_noise\" in k or \"pos_normalizer\" in k) for k in loading_return.unexpected_keys)\n",
    "    assert len(loading_return.missing_keys) == 0, f\"Missing keys: {loading_return.missing_keys}\"\n",
    "\n",
    "    if mean:\n",
    "        model.mean = mean\n",
    "    if std:\n",
    "        model.std = std\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load models\n",
    "class LoadFromFile(argparse.Action):\n",
    "    # parser.add_argument('--file', type=open, action=LoadFromFile)\n",
    "    def __call__(self, parser, namespace, values, option_string=None):\n",
    "        if values.name.endswith(\"yaml\") or values.name.endswith(\"yml\"):\n",
    "            with values as f:\n",
    "                config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "            for key in config.keys():\n",
    "                if key not in namespace:\n",
    "                    raise ValueError(f\"Unknown argument in config file: {key}\")\n",
    "            namespace.__dict__.update(config)\n",
    "        else:\n",
    "            raise ValueError(\"Configuration file must end with yaml or yml\")\n",
    "\n",
    "class LoadFromCheckpoint(argparse.Action):\n",
    "    # parser.add_argument('--file', type=open, action=LoadFromFile)\n",
    "    def __call__(self, parser, namespace, values, option_string=None):\n",
    "        hparams_path = join(dirname(values), \"hparams.yaml\")\n",
    "        if not exists(hparams_path):\n",
    "            print(\n",
    "                \"Failed to locate the checkpoint's hparams.yaml file. Relying on command line args.\"\n",
    "            )\n",
    "            return\n",
    "        with open(hparams_path, \"r\") as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        for key in config.keys():\n",
    "            if key not in namespace and key != \"prior_args\":\n",
    "                raise ValueError(f\"Unknown argument in the model checkpoint: {key}\")\n",
    "        namespace.__dict__.update(config)\n",
    "        namespace.__dict__.update(load_model=values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrappers\n",
    "class BaseWrapper(nn.Module, metaclass=ABCMeta):\n",
    "    r\"\"\"Base class for model wrappers.\n",
    "\n",
    "    Children of this class should implement the `forward` method,\n",
    "    which calls `self.model(z, pos, batch=batch)` at some point.\n",
    "    Wrappers that are applied before the REDUCE operation should return\n",
    "    the model's output, `z`, `pos`, `batch` and potentially vector\n",
    "    features`v`. Wrappers that are applied after REDUCE should only\n",
    "    return the model's output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(BaseWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.model.reset_parameters()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, z, pos, batch=None):\n",
    "        return\n",
    "\n",
    "class AtomFilter(BaseWrapper):\n",
    "    def __init__(self, model, remove_threshold):\n",
    "        super(AtomFilter, self).__init__(model)\n",
    "        self.remove_threshold = remove_threshold\n",
    "\n",
    "    def forward(self, z, pos, batch=None):\n",
    "        x, v, z, pos, batch = self.model(z, pos, batch=batch)\n",
    "\n",
    "        n_samples = len(batch.unique())\n",
    "\n",
    "        # drop atoms according to the filter\n",
    "        atom_mask = z > self.remove_threshold\n",
    "        x = x[atom_mask]\n",
    "        if v is not None:\n",
    "            v = v[atom_mask]\n",
    "        z = z[atom_mask]\n",
    "        pos = pos[atom_mask]\n",
    "        batch = batch[atom_mask]\n",
    "\n",
    "        assert len(batch.unique()) == n_samples, (\n",
    "            \"Some samples were completely filtered out by the atom filter. \"\n",
    "            f\"Make sure that at least one atom per sample exists with Z > {self.remove_threshold}.\"\n",
    "        )\n",
    "        return x, v, z, pos, batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output model \n",
    "class EquivariantScalar(OutputModel):\n",
    "    def __init__(self, hidden_channels, activation=\"silu\", allow_prior_model=True):\n",
    "        super(EquivariantScalar, self).__init__(allow_prior_model=allow_prior_model)\n",
    "        self.output_network = nn.ModuleList(\n",
    "            [\n",
    "                GatedEquivariantBlock(\n",
    "                    hidden_channels,\n",
    "                    hidden_channels // 2,\n",
    "                    activation=activation,\n",
    "                    scalar_activation=True,\n",
    "                ),\n",
    "                GatedEquivariantBlock(hidden_channels // 2, 1, activation=activation),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.output_network:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    def pre_reduce(self, x, v, z, pos, batch):\n",
    "        for layer in self.output_network:\n",
    "            x, v = layer(x, v)\n",
    "        # include v in output to make sure all parameters have a gradient\n",
    "        return x + v.sum() * 0\n",
    "\n",
    "class EquivariantVectorOutput(EquivariantScalar):\n",
    "    def __init__(self, hidden_channels, activation=\"silu\"):\n",
    "        super(EquivariantVectorOutput, self).__init__(\n",
    "            hidden_channels, activation, allow_prior_model=False\n",
    "        )\n",
    "\n",
    "    def pre_reduce(self, x, v, z, pos, batch):\n",
    "        for layer in self.output_network:\n",
    "            x, v = layer(x, v)\n",
    "        return v.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed (for reproducibility)\n",
    "pl.seed_everything(args.seed, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset that is used in this example is the `PCQM4Mv2` dataset that contains 3.4 million organic molecules, specified by their 3D structures at equilibrium calculated using DFT. \n",
    "\n",
    "The dataset contains labels, but they are not used, since pre-training only requires the structural data. \n",
    "\n",
    "#### Representation of data\n",
    "A molecular structure is specified by its atom coordinate vector $x = (x^{(1)}, \\ldots, x^{(N)}) \\in \\mathbb{R}^{3N}$, where $x^i \\in \\mathbb{R}^3$ is the position of atom $i$ in 3D.\n",
    "\n",
    "#### Noise perturbation \n",
    "The data `DataModule` loads the original dataset and a noise-perturbated version. For the noise-perturbed data, the following `transform` function is applied to the raw input data: \n",
    "```\n",
    "def transform(data):\n",
    "    noise = torch.randn_like(data.pos) * self.hparams['position_noise_scale']\n",
    "    data.pos_target = noise\n",
    "    data.pos = data.pos + noise\n",
    "    return data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 100, val 10, test 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1002749/124179684.py:71: UserWarning: 3378396 samples were excluded from the dataset\n",
      "  rank_zero_warn(f\"{dset_len - total} samples were excluded from the dataset\")\n",
      "/tmp/ipykernel_1002749/124179684.py:73: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  idxs = np.arange(dset_len, dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "# initialize data module\n",
    "data = DataModule(args)\n",
    "data.prepare_data()\n",
    "data.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class '__main__.NeighborEmbedding'> is a built-in class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# initialize lightning module\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m LNNP(args, prior_model\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, mean\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mmean, std\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mstd)\n",
      "\u001b[1;32m/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb Cell 23\u001b[0m in \u001b[0;36mLNNP.__init__\u001b[0;34m(self, hparams, prior_model, mean, std)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m load_model(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mpretrained_model, args\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams, mean\u001b[39m=\u001b[39mmean, std\u001b[39m=\u001b[39mstd)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m create_model(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhparams, prior_model, mean, std)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# initialize exponential smoothing\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mema \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb Cell 23\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(args, prior_model, mean, std)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mequivariant-transformer\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     is_equivariant \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     representation_model \u001b[39m=\u001b[39m TorchMD_ET(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         attn_activation\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mattn_activation\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m         num_heads\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mnum_heads\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m         distance_influence\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mdistance_influence\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m         layernorm_on_vec\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mlayernorm_on_vec\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mshared_args,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnknown architecture: \u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb Cell 23\u001b[0m in \u001b[0;36mTorchMD_ET.__init__\u001b[0;34m(self, hidden_channels, num_layers, num_rbf, rbf_type, trainable_rbf, activation, attn_activation, neighbor_embedding, num_heads, distance_influence, cutoff_lower, cutoff_upper, max_z, max_num_neighbors, layernorm_on_vec)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=392'>393</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance \u001b[39m=\u001b[39m Distance(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=393'>394</a>\u001b[0m     cutoff_lower,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=394'>395</a>\u001b[0m     cutoff_upper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=397'>398</a>\u001b[0m     loop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=398'>399</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=399'>400</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance_expansion \u001b[39m=\u001b[39m rbf_class_mapping[rbf_type](\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=400'>401</a>\u001b[0m     cutoff_lower, cutoff_upper, num_rbf, trainable_rbf\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=401'>402</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=402'>403</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneighbor_embedding \u001b[39m=\u001b[39m (\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=403'>404</a>\u001b[0m     NeighborEmbedding(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=404'>405</a>\u001b[0m         hidden_channels, num_rbf, cutoff_lower, cutoff_upper, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_z\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=405'>406</a>\u001b[0m     )\u001b[39m.\u001b[39;49mjittable()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=406'>407</a>\u001b[0m     \u001b[39mif\u001b[39;00m neighbor_embedding\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=407'>408</a>\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=408'>409</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=410'>411</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_layers \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=411'>412</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_layers):\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:530\u001b[0m, in \u001b[0;36mMessagePassing.jittable\u001b[0;34m(self, typing)\u001b[0m\n\u001b[1;32m    525\u001b[0m     prop_types \u001b[39m=\u001b[39m {\n\u001b[1;32m    526\u001b[0m         k: sanitize(\u001b[39mstr\u001b[39m(v))\n\u001b[1;32m    527\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate_type\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    528\u001b[0m     }\n\u001b[1;32m    529\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m     source \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mgetsource(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)\n\u001b[1;32m    531\u001b[0m     match \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*propagate_type:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m((.*)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m, source)\n\u001b[1;32m    532\u001b[0m     \u001b[39mif\u001b[39;00m match \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/inspect.py:1024\u001b[0m, in \u001b[0;36mgetsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetsource\u001b[39m(\u001b[39mobject\u001b[39m):\n\u001b[1;32m   1019\u001b[0m     \u001b[39m\"\"\"Return the text of the source code for an object.\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \n\u001b[1;32m   1021\u001b[0m \u001b[39m    The argument may be a module, class, method, function, traceback, frame,\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[39m    or code object.  The source code is returned as a single string.  An\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[39m    OSError is raised if the source code cannot be retrieved.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m     lines, lnum \u001b[39m=\u001b[39m getsourcelines(\u001b[39mobject\u001b[39;49m)\n\u001b[1;32m   1025\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(lines)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/inspect.py:1006\u001b[0m, in \u001b[0;36mgetsourcelines\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[39m\"\"\"Return a list of source lines and starting line number for an object.\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \n\u001b[1;32m   1000\u001b[0m \u001b[39mThe argument may be a module, class, method, function, traceback, frame,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[39moriginal source file the first line of code was found.  An OSError is\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[39mraised if the source code cannot be retrieved.\"\"\"\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \u001b[39mobject\u001b[39m \u001b[39m=\u001b[39m unwrap(\u001b[39mobject\u001b[39m)\n\u001b[0;32m-> 1006\u001b[0m lines, lnum \u001b[39m=\u001b[39m findsource(\u001b[39mobject\u001b[39;49m)\n\u001b[1;32m   1008\u001b[0m \u001b[39mif\u001b[39;00m istraceback(\u001b[39mobject\u001b[39m):\n\u001b[1;32m   1009\u001b[0m     \u001b[39mobject\u001b[39m \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39mtb_frame\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/inspect.py:817\u001b[0m, in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfindsource\u001b[39m(\u001b[39mobject\u001b[39m):\n\u001b[1;32m    810\u001b[0m     \u001b[39m\"\"\"Return the entire source file and starting line number for an object.\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \n\u001b[1;32m    812\u001b[0m \u001b[39m    The argument may be a module, class, method, function, traceback, frame,\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[39m    or code object.  The source code is returned as a list of all the lines\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[39m    in the file and the line number indexes a line in that list.  An OSError\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[39m    is raised if the source code cannot be retrieved.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m     file \u001b[39m=\u001b[39m getsourcefile(\u001b[39mobject\u001b[39;49m)\n\u001b[1;32m    818\u001b[0m     \u001b[39mif\u001b[39;00m file:\n\u001b[1;32m    819\u001b[0m         \u001b[39m# Invalidate cache if needed.\u001b[39;00m\n\u001b[1;32m    820\u001b[0m         linecache\u001b[39m.\u001b[39mcheckcache(file)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/inspect.py:697\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetsourcefile\u001b[39m(\u001b[39mobject\u001b[39m):\n\u001b[1;32m    694\u001b[0m     \u001b[39m\"\"\"Return the filename that can be used to locate an object's source.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39m    Return None if no way can be identified to get the source.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 697\u001b[0m     filename \u001b[39m=\u001b[39m getfile(\u001b[39mobject\u001b[39;49m)\n\u001b[1;32m    698\u001b[0m     all_bytecode_suffixes \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mmachinery\u001b[39m.\u001b[39mDEBUG_BYTECODE_SUFFIXES[:]\n\u001b[1;32m    699\u001b[0m     all_bytecode_suffixes \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mmachinery\u001b[39m.\u001b[39mOPTIMIZED_BYTECODE_SUFFIXES[:]\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/site-packages/torch/package/package_importer.py:620\u001b[0m, in \u001b[0;36mpatched_getfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39min\u001b[39;00m _package_imported_modules:\n\u001b[1;32m    619\u001b[0m         \u001b[39mreturn\u001b[39;00m _package_imported_modules[\u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m]\u001b[39m.\u001b[39m\u001b[39m__file__\u001b[39m\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m _orig_getfile(\u001b[39mobject\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/inspect.py:666\u001b[0m, in \u001b[0;36mgetfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, \u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    665\u001b[0m             \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m\u001b[39m__file__\u001b[39m\n\u001b[0;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m is a built-in class\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mobject\u001b[39m))\n\u001b[1;32m    667\u001b[0m \u001b[39mif\u001b[39;00m ismethod(\u001b[39mobject\u001b[39m):\n\u001b[1;32m    668\u001b[0m     \u001b[39mobject\u001b[39m \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__func__\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: <class '__main__.NeighborEmbedding'> is a built-in class"
     ]
    }
   ],
   "source": [
    "# initialize lightning module\n",
    "model = LNNP(args, prior_model=None, mean=data.mean, std=data.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from typing import Optional, List, Tuple\n",
    "# import torch\n",
    "# from torch.autograd import grad\n",
    "# from torch import nn\n",
    "# from torch_scatter import scatter\n",
    "# from pytorch_lightning.utilities import rank_zero_warn\n",
    "# from torchmdnet.models import output_modules\n",
    "# from torchmdnet.models.wrappers import AtomFilter\n",
    "# from torchmdnet import priors\n",
    "# import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_model_noise = 'VectorOutput'\n",
    "# position_noise_scale = 0.04\n",
    "\n",
    "# model = TorchMD_Net(\n",
    "#     representation_model=AtomFilter(\n",
    "#         TorchMD_ET(\n",
    "#             attn_activation=args[\"attn_activation\"],\n",
    "#             num_heads=args[\"num_heads\"],\n",
    "#             distance_influence=args[\"distance_influence\"],\n",
    "#             layernorm_on_vec=args[\"layernorm_on_vec\"],\n",
    "#             **shared_args,\n",
    "#         ), \n",
    "#         args[\"atom_filter\"]\n",
    "#     ),\n",
    "#     output_model = EquivariantScalar(args[\"embedding_dimension\"], args[\"activation\"]),\n",
    "#     prior_model=prior_model,\n",
    "#     reduce_op=args[\"reduce_op\"],\n",
    "#     mean=mean,\n",
    "#     std=std,\n",
    "#     derivative=args[\"derivative\"],\n",
    "#     output_model_noise=EquivariantVectorOutput(args[\"embedding_dimension\"], args[\"activation\"]),\n",
    "#     position_noise_scale=args['position_noise_scale'],\n",
    "# )\n",
    "\n",
    "\n",
    "# class TorchMD_Net(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         representation_model,\n",
    "#         output_model,\n",
    "#         reduce_op=\"add\",\n",
    "#         mean=None,\n",
    "#         std=None,\n",
    "#         output_model_noise=None,\n",
    "#         position_noise_scale=0.,\n",
    "#     ):    \n",
    "#         super(TorchMD_Net, self).__init__()\n",
    "#         self.representation_model = representation_model\n",
    "#         self.output_model = output_model\n",
    "\n",
    "#         self.pos_normalizer = AccumulatedNormalization(accumulator_shape=(3,)) # (batch - self.mean) / self.std\n",
    "\n",
    "#     def forward(self, z, pos, batch: Optional[torch.Tensor] = None):\n",
    "#         batch = torch.zeros_like(z) if batch is None else batch\n",
    "\n",
    "#         # run the potentially wrapped representation model\n",
    "#         x, v, z, pos, batch = self.representation_model(z, pos, batch=batch)\n",
    "\n",
    "#         # predict noise -> predict next noisy position 'pos'\n",
    "#         noise_pred = self.output_model_noise.pre_reduce(x, v, z, pos, batch) \n",
    "\n",
    "        \n",
    "\n",
    "# class LNNP(LightningModule):\n",
    "#     def step(self, batch, loss_fn, stage):\n",
    "#         pred, noise_pred, deriv = self(batch.z, batch.pos, batch.batch)\n",
    "#         pred = pred + noise_pred.sum() * 0\n",
    "                    \n",
    "#         # normalization -> model.pos_normalizer = AccumulatedNormalization(accumulator_shape=(3,))\n",
    "#         # normalized_pos_target = (batch - self.mean) / self.std\n",
    "#         normalized_pos_target = self.model.pos_normalizer(batch.pos_target)\n",
    "        \n",
    "#         # loss_fn takes MSE loss || GNN_{\\theta}(\\tilde{S}) - (\\varepsilon_1, \\ldots, \\varepsilon_{|S|})||^2\n",
    "#         loss_pos = loss_fn(noise_pred, normalized_pos_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logging\n",
    "tb_logger = pl.loggers.TensorBoardLogger(\n",
    "    args.log_dir, name=\"tensorbord\", version=\"\", default_hp_metric=False\n",
    ")\n",
    "csv_logger = CSVLogger(args.log_dir, name=\"\", version=\"\")\n",
    "wandb_logger = WandbLogger(name=args.job_id, project='pre-training-via-denoising', notes=args.wandb_notes, settings=wandb.Settings(start_method='fork', code_dir=\".\"))\n",
    "\n",
    "@rank_zero_only\n",
    "def log_code():\n",
    "    wandb_logger.experiment # runs wandb.init, so then code can be logged next\n",
    "    wandb.run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".yaml\"))\n",
    "\n",
    "log_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clongo/miniconda3/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:523: UserWarning: You requested multiple GPUs but did not specify a backend, e.g. `Trainer(accelerator=\"dp\"|\"ddp\"|\"ddp2\")`. Setting `accelerator=\"ddp_spawn\"` for you.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=3, # args.num_epochs,\n",
    "    max_steps=400, #args.num_steps,\n",
    "    gpus=1, # args.ngpus,\n",
    "    num_nodes=1, # args.num_nodes,\n",
    "    accelerator=None, # args.distributed_backend,\n",
    "    default_root_dir=\"experiments/\", # args.log_dir,\n",
    "    auto_lr_find=False, # False,\n",
    "    resume_from_checkpoint=None, # args.load_model,\n",
    "    callbacks=None,\n",
    "    logger=[tb_logger, wandb_logger], # [tb_logger, csv_logger, wandb_logger],\n",
    "    reload_dataloaders_every_epoch=False, # False,\n",
    "    precision=32, # args.precision,\n",
    "    plugins=None, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'DataModule.setup.<locals>.transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmikoto.aer.mw.tum.de/home/clongo/pre-training-via-denoising/minimal_working_example.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:460\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39m# links data to the trainer\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    457\u001b[0m     model, train_dataloader\u001b[39m=\u001b[39mtrain_dataloader, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    458\u001b[0m )\n\u001b[0;32m--> 460\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model)\n\u001b[1;32m    462\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    463\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:758\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_dispatch()\n\u001b[1;32m    757\u001b[0m \u001b[39m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch()\n\u001b[1;32m    760\u001b[0m \u001b[39m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_dispatch()\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:799\u001b[0m, in \u001b[0;36mTrainer.dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mstart_predicting(\u001b[39mself\u001b[39m)\n\u001b[1;32m    798\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 799\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mstart_training(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py:96\u001b[0m, in \u001b[0;36mAccelerator.start_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart_training\u001b[39m(\u001b[39mself\u001b[39m, trainer: \u001b[39m'\u001b[39m\u001b[39mpl.Trainer\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_type_plugin\u001b[39m.\u001b[39;49mstart_training(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/ddp_spawn.py:122\u001b[0m, in \u001b[0;36mDDPSpawnPlugin.start_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart_training\u001b[39m(\u001b[39mself\u001b[39m, trainer):\n\u001b[0;32m--> 122\u001b[0m     mp\u001b[39m.\u001b[39;49mspawn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_process, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmp_spawn_kwargs)\n\u001b[1;32m    123\u001b[0m     \u001b[39m# reset optimizers, since main process is never used for training and thus does not have a valid optim state\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     trainer\u001b[39m.\u001b[39moptimizers \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:230\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    226\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mThis method only supports start_method=spawn (got: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    227\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mTo use a different start_method use:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    228\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m start_method)\n\u001b[1;32m    229\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 230\u001b[0m \u001b[39mreturn\u001b[39;00m start_processes(fn, args, nprocs, join, daemon, start_method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspawn\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:179\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    173\u001b[0m error_queue \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39mSimpleQueue()\n\u001b[1;32m    174\u001b[0m process \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39mProcess(\n\u001b[1;32m    175\u001b[0m     target\u001b[39m=\u001b[39m_wrap,\n\u001b[1;32m    176\u001b[0m     args\u001b[39m=\u001b[39m(fn, i, args, error_queue),\n\u001b[1;32m    177\u001b[0m     daemon\u001b[39m=\u001b[39mdaemon,\n\u001b[1;32m    178\u001b[0m )\n\u001b[0;32m--> 179\u001b[0m process\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    180\u001b[0m error_queues\u001b[39m.\u001b[39mappend(error_queue)\n\u001b[1;32m    181\u001b[0m processes\u001b[39m.\u001b[39mappend(process)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, fp)\n\u001b[1;32m     48\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pvd/lib/python3.9/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'DataModule.setup.<locals>.transform'"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # run test set after completing the fit\n",
    "trainer.test()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
